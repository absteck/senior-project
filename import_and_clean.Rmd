---
title: "Import and Clean"
author: "Abby Steckel"
date: "10/4/2021"
output:
  html_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Set working directory
```{r}
setwd("/Users/abbysteckel/Desktop/S&DS_491/sentencing_data/")
```

### Attempt to read ASCII text data
```{r}
#error: line 1 did not have 75 elements
#not sure why it thinks there are only 75 elements, should be hundreds 
# text2 <- read.table("/Users/abbysteckel/Desktop/ASCII_2000/DS0001/ASCII_2000_data.txt", as.is = TRUE, header = F) #error: Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec, : line 1 did not have 75 elements
```

The only other file format available for 2000-2005 is SAS. The data is stored in the same .txt file as ASCII and SPSS, with a .sas setup file. I will use the SPSS data because I saw an example use of asciiSetupReader to parse a .sps setup file. 

### Read SPSS .sav data using foreign package
```{r, eval=FALSE}
library(foreign)
spss_2006_data <- read.spss("spss_2006_data.sav", to.data.frame=TRUE, use.value.labels = FALSE, reencode = "windows-1252")
#head(spss_2006_data)
d06 <- spss_2006_data
names(d06)[1:10] #variables have correct names 
dim(d06) #72585 x 825 

#gets same dimensions and same variable names as haven package. seems like both haven and foreign work well when the data is in a .sav file format 
```

### comparing .sav import in R to import in Python 
```{r, eval=FALSE}
test <- d06$SENTTOT
length(test) #72585
sum(is.na(test)) #9622 NAs 
length(na.omit(test)) #62963 not NA 
str(test) #mostly numeric except "990 months or more" and "life"... I am assuming that "990 months or more" is a named numeric variable with label 990, and "life" has numeric name 470 
# "attr(*, "value.labels") = Named num [1:2] 990 470" 

#can I change val labels using the 'labelled' package? alas, haven't been successful thus far
library(labelled)
val_labels(test) #NULL 
summary(test)

count_life <- 0
for(i in na.omit(test)){
  if(i == 470){
    count_life<- count_life + 1
  }
}
count_life #358 life sentences, consistent with Python 

count_990 <- 0

for(i in na.omit(test)){
  if(i == 990){
    count_990 <- count_990 + 1
  }
}

count_990 #0 sentences of 990 months. This is consistent with my Python result and with the below table
rev(table(test)) #the values in the table seem reasonable. there are no negative values. 
table(test < 0)

length(unique(test)) #1116 unique values. Python lists 1115. This is because R considers 'NA' a value, while Python does not  
length(unique(test[is.na(test) == FALSE]))

mean(test, na.rm=TRUE) #59.11379, consistent with Python 

#indices of columns to select in Python 
which(names(data2000) %in% c("SENTTOT", "AGE", "MONSEX", "EDUCATN", "HISPORIG", "CITIZEN", "CRIMHIST", "XCRHISSR", "NOCOUNTS", "CRIMPTS", "NEWCNVTN", "SENTDATE", "DISTRICT", "OFFTYPE2"))
```
*Based on the above, I think the 2006 data was imported cleanly. For the response variable, the number of NAs, the number of unique values, the minimum and maximum, the number of life sentences, and the mean are consistent between import results in R and Python. Because it seems unlikely that different packages on different software would make the exact same mistakes, I assume that my method of importing .sav files in R is reliable.*

## Read SPSS data using ASCII Setup Reader and foreign packages 
```{r}
library(asciiSetupReader)
#2000 DATA 
setup2000 <- asciiSetupReader::parse_setup('spss_2000_setup.sps')
setup2000$setup 
setup2000$missing

data2000 <- read_ascii_setup("spss_2000_data.txt.zip", "spss_2000_setup.sps", use_clean_names = FALSE)
head(data2000)
#dim(data2000)

#2001 DATA 
setup2001 <- asciiSetupReader::parse_setup('spss_2001_setup.sps')
#setup2001$setup #255 columns 
#setup2001$missing # no missing values 
data2001 <- read_ascii_setup("spss_2001_data.txt.zip", "spss_2001_setup.sps", use_clean_names = FALSE)
#head(data2001)

#2002 DATA 
setup2002 <- asciiSetupReader::parse_setup('spss_2002_setup.sps')
#setup2002$setup #302 columns 
#setup2002$missing # no missing values 
data2002 <- read_ascii_setup("spss_2002_data.txt.zip", "spss_2002_setup.sps", use_clean_names = FALSE)

#2003 DATA 
setup2003 <- asciiSetupReader::parse_setup('spss_2003_setup.sps')
#setup2003$setup #306 columns 
#setup2003$missing # no missing values 
data2003 <- read_ascii_setup("spss_2003_data.txt.zip", "spss_2003_setup.sps", use_clean_names = FALSE)

#2004 DATA 
setup2004 <- asciiSetupReader::parse_setup('spss_2004_setup.sps')
#setup2004$setup #459 columns 
#setup2004$missing # no missing values 
data2004 <- read_ascii_setup("spss_2004_data.txt.zip", "spss_2004_setup.sps", use_clean_names = FALSE)

#2005 DATA 
setup2005 <- asciiSetupReader::parse_setup('spss_2005_setup.sps')
#setup2005$setup #491 columns 
#setup2005$missing # no missing values 
data2005 <- read_ascii_setup("spss_2005_data.txt.zip", "spss_2005_setup.sps", use_clean_names = FALSE)

#2006 DATA - note switch to .sav extension. When I read in, I get message: "re-encoding from CP1252," which may indicate that the numeric values of factors will change
library(foreign)
#data2006_default_reencode <- read.spss("spss_2006_data.sav", to.data.frame=TRUE, use.value.labels = FALSE)

#what about when we specify that assumed encoding is CP1252? still gives me a "reencoding from windows 1252," not sure if this indicates an eror or just visibility

data2006 <- read.spss("spss_2006_data.sav", to.data.frame=TRUE, use.value.labels = FALSE, reencode = "windows-1252")

#library(arsenal)
#compare_cp1252 <- comparedf(data2006, data2006_default_reencode)
#summary(compare_cp1252) #only one observation not the same, and not a variable that I care about

#check if factors have expected values 
sort(unique(data2006$EDUCATN)) #yes. values are 0-37, consistent with codebook p. 45
sort(unique(data2006$MONRACE)) #yes. values: 1, 2, 3, 4, 5, 7
sort(unique(data2006$XCRHISSR)) #yes. values: 1-6. 
table(data2006$MONSEX) #yes. 0 and 1, with 1 being much more frequent. 
#factors have the expected values, and at least for sex, the expected frequency. I'm going to trust that re-encoding from CP 1252 is not distorting the data. 

#2007 DATA 
data2007 <- read.spss("spss_2007_data.sav", to.data.frame=TRUE, use.value.labels = FALSE, reencode = "windows-1252")

#2008 DATA 
data2008 <- read.spss("spss_2008_data.sav", to.data.frame=TRUE, use.value.labels = FALSE, reencode = "windows-1252")
```

### Select variables for use in models 
```{r}
#These are the same variables that Hagen selected from the BJS dataset, except for OFFTYPE2, which I'm using instead of TTIGRON 

#REMOVE CRPTS AFTER COMPARING TO HAGEN
#from 2000-2003, there was a sentdate variable. beginning in 2004, it became sentyr and sentmon 
vars00 <- c("SENTTOT", "AGE", "MONSEX", "EDUCATN", "HISPORIG", "CITIZEN", "CRIMHIST", "XCRHISSR", "NOCOUNTS", "CRIMPTS", "NEWCNVTN", "SENTDATE", "DISTRICT", "OFFTYPE2", "CRPTS", "MONRACE")

vars04 <- c("SENTTOT", "AGE", "MONSEX", "EDUCATN", "HISPORIG", "CITIZEN", "CRIMHIST", "XCRHISSR", "NOCOUNTS", "CRIMPTS", "NEWCNVTN", "SENTYR", "DISTRICT", "OFFTYPE2", "CRPTS", "MONRACE")
```

### Rename variables and force same data types across years 
```{r}
#REMOVE CRPTS AFTER TESTING
#rename columns to have the same names as Hagen assigned
hagen_names <- c("SENTENCE", "AGE", "MALE", "EDUCATN", "HISPANIC", "USCITIZEN", "CRIMINAL", "CATEGORY", "NOCOUNTS", "POINTS", "TRIAL", "YR", "DISTRICT", "PRIM_OFFENSE", "CRPTS", "RACE")

renameHagen <- function(df, old_names){
  for(i in 1:length(old_names)){
    names(df)[names(df) == old_names[i]] <- hagen_names[i]
  }
  return(df)
}

data2008 <- renameHagen(data2008, vars04)
data2007 <- renameHagen(data2007, vars04)
data2006 <- renameHagen(data2006, vars04)
data2005 <- renameHagen(data2005, vars04)
data2004 <- renameHagen(data2004, vars04)
data2003 <- renameHagen(data2003, vars00)
data2002 <- renameHagen(data2002, vars00)
data2001 <- renameHagen(data2001, vars00)
data2000 <- renameHagen(data2000, vars00)

#subset each dataset to just the columns of interest
data2000 <- data2000[,hagen_names]
data2001 <- data2001[,hagen_names]
data2002 <- data2002[,hagen_names]
data2003 <- data2003[,hagen_names]
data2004 <- data2004[,hagen_names]
data2005 <- data2005[,hagen_names]
data2006 <- data2006[,hagen_names]
data2007 <- data2007[,hagen_names]
data2008 <- data2008[,hagen_names]

# #function to get year from format d(d)m(m)yyyy
# getyr <- function(date){
#   date <- as.character(date)
#   len <- nchar(date)
#   yr <- substr(date, len-3, len)
#   return(yr)
# }
# #for 2000-2004 dates, create new YR variable that just contains the year of sentencing
# data2000$YR <- getyr(data2000$YR)
# data2001$YR <- getyr(data2001$YR)
# data2002$YR <- getyr(data2002$YR)
# data2003$YR <- getyr(data2003$YR)
# data2004$YR <- getyr(data2004$YR)
data2000$YR <- "99_00"
data2001$YR <- "00_01"
data2002$YR <- "01_02"
data2003$YR <- "02_03"
data2004$YR <- "03_04"
data2005$YR <- "04_05"
data2006$YR <- "05_06"
data2007$YR <- "06_07" 
data2008$YR <- "07_08"
#data types: 
#sentence in 2006, 2007, 2008 is a factor 
#age: num 
#male: factor in 06-08 
#education: char in 2000-2005, factor in 2006-2008 
#hispanic: "
#uscitizen "
#criminal: char in 2000-2003, num in 2005, factor in 2006-2008 
#category: num 
#nocounts: num 
#points: char in 2000-05, factor 06-08
#trial: char 2000-05, factor 
#yr: char 2000-04, then num 
#district: num 2000-06, factor 07-08 
#prim_offense: char 2000-05, factor 06-08

#I converted all variables except age, number of counts, category, and district data to characters for ease of combining dataframes from different years, which may have used different data types . 
#I will convert each variable to the appropriate data type after combining 

#REMOVE CRPTS AFTER TESTING
#variables to convert to characters 
char_vars <- c("SENTENCE", "MALE", "EDUCATN", "HISPANIC", "USCITIZEN", "CRIMINAL", "POINTS", "TRIAL", "PRIM_OFFENSE", "CRPTS", "RACE")

#would like to figure out how perform the same operation on the list of dfs
#dfs <- list(data2000, data2001, data2002, data2003, data2004, data2005, data2006, data2007, data2008) 

for(var in char_vars){
  data2000[,var] <- as.character(data2000[,var])
}
for(var in char_vars){
  data2001[,var] <- as.character(data2001[,var])
}
for(var in char_vars){
  data2002[,var] <- as.character(data2002[,var])
}
for(var in char_vars){
  data2003[,var] <- as.character(data2003[,var])
}
for(var in char_vars){
  data2004[,var] <- as.character(data2004[,var])
}
for(var in char_vars){
  data2005[,var] <- as.character(data2005[,var])
}
for(var in char_vars){
  data2006[,var] <- as.character(data2006[,var])
}
for(var in char_vars){
  data2007[,var] <- as.character(data2007[,var])
}
for(var in char_vars){
  data2008[,var] <- as.character(data2008[,var])
}
data2007$DISTRICT <- as.numeric(data2007$DISTRICT)
data2008$DISTRICT <- as.numeric(data2008$DISTRICT)
```

### Combine data for all years 
```{r}
library(dplyr)
combine <- bind_rows(data2000, data2001, data2002, data2003, data2004, data2005, data2006, data2007, data2008)

if(nrow(data2000) + nrow(data2001) + nrow(data2002) + nrow(data2003) + nrow(data2004) + nrow(data2005) + nrow(data2006) + nrow(data2007) + nrow(data2008) != nrow(combine)){
  print("dimension mismatch")
} 

nrow(combine[complete.cases(na_if(combine, "")),]) #if we replace all blanks with NAs, # of complete rows = 422338
nrow(combine) #total number of observations = 618825 

# #check missingness of a couple columns compared to Hagen's Table 1
sum(is.na(combine$AGE)==FALSE) #603635: same number of age observations as Hagen
sum(is.na(combine$NOCOUNTS) == FALSE) #616935: consistent with Hagen 

sum(is.na(combine$SENTENCE) == FALSE) #number of sentence observations = 525574. Hagen: 525509
# rev(table(combine$SENTENCE))
summary(as.numeric(gsub("990 months or more", 990, gsub("life", 470, tolower(combine$SENTENCE)))), na.rm = TRUE) #no negative values. max = 11520, consistent with Hagen. but min = 0.0 while Hagen min = 0.3 
```

### Writing and reading .csv.gz files
```{r}
# write combined data to compressed file 
# library(crunch)
# write.csv.gz(combine, "/Users/abbysteckel/Desktop/combined.csv.gz")

# library(R.utils)
# test <- read.csv('/Users/abbysteckel/Desktop/test.csv.gz')
# 
# combine <- read.csv('/Users/abbysteckel/Desktop/combined.csv.gz')
# 
# head(combine)
# dim(combine) 
# #problem: blank spaces won't be filtered out by na.omit or complete.cases 
# library(tidyverse)
# combine <- na_if(combine, "")
```

### Reformatting data  
```{r}
#Create indicators for year of sentencing 
combine$YR2000 <- ifelse(combine$YR == "99_00", 1, 0) 
combine$YR2001 <- ifelse(combine$YR == "00_01", 1, 0)
combine$YR2002 <- ifelse(combine$YR == "01_02", 1, 0)
combine$YR2003 <- ifelse(combine$YR == "02_03", 1, 0)
combine$YR2004 <- ifelse(combine$YR == "03_04", 1, 0)
combine$YR2005 <- ifelse(combine$YR == "04_05", 1, 0)
combine$YR2006 <- ifelse(combine$YR == "05_06", 1, 0)
combine$YR2007 <- ifelse(combine$YR == "06_07", 1, 0)
combine$YR2008 <- ifelse(combine$YR == "07_08", 1, 0)

#unique(tolower(combine$EDUCATN)) #NAs should remain NAs! 
#create indicators for highest education level achieved. note that there was slight variation in the level labels between years, hence the need for a bit of cleaning
#if education = "high school graduate" or "GED (general education diploma)", or corresponding numeric levels  
combine$HSGED <- rep(200, length(combine$EDUCATN)) #create an array of 200s (200 is an arbitrary placeholder instead of NA)
combine$HSGED[tolower(combine$EDUCATN) %in% c("g.e.d.", "high school graduate", "g.e.d. (general education diploma)", "12", "21")] <- 1
combine$HSGED[!is.na(combine$EDUCATN) & combine$HSGED!= 1] <- 0 
combine$HSGED[combine$HSGED == 200] <- NA

#if education = "one year of college / freshman", "two years of college / sophomore", "three years of college / junior", "some trade or vocational school", "some college" 
combine$SOMEPOSTHS <- rep(200, length(combine$EDUCATN)) 
combine$SOMEPOSTHS[tolower(combine$EDUCATN) %in% c("three years college", "some college", "three years of college /junior", "two years of college /sophomore", "one year of college /freshman", "some trade or vocational school", "two years of college/sophomore", "one year of college/freshman", "two years of college / sophomore", "one year of college / freshman", "three years of college / junior", "some trade/vocationl", "one year of college", "two years of college", "13", "14", "15","33", "34")] <- 1
combine$SOMEPOSTHS[!is.na(combine$EDUCATN) & combine$SOMEPOSTHS != 1 ] <- 0
combine$SOMEPOSTHS[combine$SOMEPOSTHS ==200] <- NA

#if education = "college graduate", "Trade or vocational degree", "Associate degree (A.A.)", "Graduate degree (MST, J.D., M.D., PH.D., etc)", "Some graduate school" 
combine$POSTHSDEGREE <- rep(200, length(combine$EDUCATN))
combine$POSTHSDEGREE[tolower(combine$EDUCATN) %in% c("college graduate", "grad degree", "associate degree", "grad degree (mst, j.d., m.d., ph.d., etc", "graduate degree (mst, j.d., m.d., ph.d., etc)", "trade/vocational deg", "some graduate school", "trade or vocational degree", "associate degree (a.a.)", "16", "22", "23", "24", "35")] <- 1
combine$POSTHSDEGREE[!is.na(combine$EDUCATN) & combine$POSTHSDEGREE != 1 ] <- 0
combine$POSTHSDEGREE[combine$POSTHSDEGREE == 200] <- NA

#for SENTENCE data, I will set "990 months or more" to "990"   
combine$SENTENCE <- gsub("^990.*","990", combine$SENTENCE) 
table(combine$SENTENCE == "990") #29 people sentenced to 990 months or more 
table(tolower(combine$SENTENCE) == "life") #1206 sentenced to life 

#average life expectancy for Hispanic Americans is 81.8 years or 981.6 months 
combine$SENTENCE[tolower(combine$SENTENCE) %in% c("life") & combine$HISPANIC %in% c("Hispanic", "2")] <- 981.6

combine$SENTENCE[tolower(combine$SENTENCE) %in% c("life")] <- 945.6 #non-Hispanic people or people with unknown ethnicity have an average life expectancy of 78.8 years/945.6 months 

#create SWB indicator of whether the case district is in the Southwest Border region
#there are no NA values for dDISTRICT, so it's ok to use ifelse()
combine$SWB <- ifelse(combine$DISTRICT %in% c(41, 42, 84, 70, 74), 1, 0)

#create offense category indicators
combine$CATEGORY2 <- ifelse(combine$CATEGORY == 2, 1, 0)
combine$CATEGORY3 <- ifelse(combine$CATEGORY == 3, 1, 0)
combine$CATEGORY4 <- ifelse(combine$CATEGORY == 4, 1, 0)
combine$CATEGORY5 <- ifelse(combine$CATEGORY == 5, 1, 0)
combine$CATEGORY6 <- ifelse(combine$CATEGORY == 6, 1, 0)

#convert to correct data types - careful with NA handling! 
combine$SENTENCE <- as.numeric(combine$SENTENCE) #NAs passed through as.numeric() remain NAs
combine$AGE <- as.numeric(combine$AGE) 

combine$MALE[combine$MALE == "0"] <- "Male" #"Male" was originally coded as 0
combine$MALE[combine$MALE == "1"] <- "Female" 
combine$MALE[combine$MALE == "Male"] <- 1 #recode Male as 1 to match Hagen
combine$MALE[combine$MALE == "Female"] <- 0
combine$MALE <- as.numeric(combine$MALE)

combine$HISPANIC[tolower(combine$HISPANIC) %in% c("non-hispanic", "1", "0")] <- 0
combine$HISPANIC[combine$HISPANIC %in% c("Hispanic", "2")] <- 1
combine$HISPANIC[combine$HISPANIC %in% c("Information Not Available")] <- NA 
combine$HISPANIC <- as.numeric(combine$HISPANIC) 

combine$USCITIZEN[tolower(combine$USCITIZEN) %in% c("united states citizen", "united states citzen", "1")] <- 1
combine$USCITIZEN[tolower(combine$USCITIZEN) %in% c("resident/legal alien", "illegal alien", "not a us citizen/alien status unknown", "not us citizen","2", "3", "4")] <- 0
combine$USCITIZEN[combine$USCITIZEN == "5"] <- NA
combine$USCITIZEN <- as.numeric(combine$USCITIZEN)

combine$CRIMINAL[tolower(combine$CRIMINAL) %in% c("no criminal history", "0")] <- 0
combine$CRIMINAL[tolower(combine$CRIMINAL) %in% c("yes, there is criminal history", "yes, criminal histy", "1")] <- 1
combine$CRIMINAL <- as.numeric(combine$CRIMINAL)

combine$TRIAL[combine$TRIAL %in% c("Trial")] <- 1
combine$TRIAL[combine$TRIAL %in% c("Plea")] <- 0
combine$TRIAL <- as.numeric(combine$TRIAL)

combine$POINTS[tolower(combine$POINTS) == "no history pts appld"] <- 0
combine$POINTS[tolower(combine$POINTS) == "no history points applied"] <- 0
combine$POINTS <- as.numeric(combine$POINTS)
combine$NOCOUNTS <- as.numeric(combine$NOCOUNTS)
combine$CRPTS[tolower(combine$CRPTS) %in% c("no history pts award", "no criminal history points applied", "0")] <- 0
combine$CRPTS[tolower(combine$CRPTS) %in% c("history pts awarded", "yes, criminal history points", "1")] <- 1
combine$CRPTS <- as.numeric(combine$CRPTS)

combine$RACE[combine$RACE %in% c("White/Caucasian", "1")] <- "white"
combine$RACE[combine$RACE %in% c("Black", "2")] <- "black"
combine$RACE[combine$RACE %in% c("Am Indn/Alask Native", "American Indian or Alaskan Native", "3")] <- "aian"
combine$RACE[combine$RACE %in% c("Asian or Pacific Islander", "Asian/Pacifc Islandr", "4")] <- "apic"
combine$RACE[combine$RACE %in% c("Multi-racial", "5")] <- "multi"
combine$RACE[combine$RACE %in% c("Other", "7")] <- "other"
#from 2007 codebook, 8 = "Info on race not available". I'll recode as NA 
combine$RACE[combine$RACE =="8"] <- NA
```

### Recoding primary offense variable 
```{r}
#sort(unique(tolower(combine$PRIM_OFFENSE)))
combine$PRIM_OFFENSE[tolower(combine$PRIM_OFFENSE) %in% c("1", "2", "3", "4", "5", "6", "assault", "bank robbery", "bank robbery (includes offtype 7, other", "kidnaping /hostage", "kidnaping/hostage", "manslaughter", "murder", "sexual abuse")] <- "violent"
sum(combine$PRIM_OFFENSE == "violent", na.rm = TRUE) #22013. Hagen: 21593
combine$PRIM_OFFENSE[tolower(combine$PRIM_OFFENSE) %in% c("firearms: use (includes offtype 14, fire", "firearms:use", "13", "14")] <- "weapons"
sum(combine$PRIM_OFFENSE == "weapons", na.rm=TRUE) #61762. Hagen: 62147
combine$PRIM_OFFENSE[tolower(combine$PRIM_OFFENSE) %in% c("immigration", "27")] <- "immigration"
sum(combine$PRIM_OFFENSE == "immigration", na.rm = TRUE) #138993. Hagen = 129976 

combine$PRIM_OFFENSE[tolower(combine$PRIM_OFFENSE) %in% c("drugs: communication facilities", "drugs: simple possession", "drugs: trafficking", "drugs:comm facils","drugs:smpl posses", "drugs:trafficking", "10", "11", "12")] <- "drugs"
sum(combine$PRIM_OFFENSE == "drugs", na.rm = TRUE) #229984. Hagen: 232010

combine$PRIM_OFFENSE[tolower(combine$PRIM_OFFENSE) %in% c("gambling / lottery","gambling/lottery","pornography / prostitution","pornography/prostitn", "25", "28")] <- "public order"
sum(combine$PRIM_OFFENSE == "public order", na.rm = TRUE) #10003. Hagen: 53895. I must be missing several crimes in this category. 

combine$PRIM_OFFENSE[tolower(combine$PRIM_OFFENSE) %in% c("arson", "9", "brglry/break & enter", "burglary/breaking and entering", "15", "auto theft", "16", "larceny", "17")] <- "property"
sum(combine$PRIM_OFFENSE == "property", na.rm = TRUE) #20562. Hagen: 117,274. I'm clearly leaving out a lot here. 
```

### Tabulating data, Comparing to Hagen Table 1 
```{r}
#Hagen num obs: 525509. my num obs: 525574 - INCONSISTENT. I have 65 more observations than Hagen. 
#average sentence: 58.1135. Hagen: 56.782 - INCONSISTENT. might have to do with how we recoded Life sentences? 
sum(!is.na(combine$SENTENCE)) - sum(combine$SENTENCE == 0, na.rm = TRUE)
summary(combine$SENTENCE) 
sum(combine$SENTENCE == 0, na.rm = TRUE) #1262 zeroes 
mean(combine$SENTENCE, na.rm = TRUE) 
table(combine$SENTENCE, useNA = "always") #no obvious place where 65 observations would have been added/coerced from NAs

#num obs: 603635, consistent with Hagen 
#average age: 34.52, consistent with Hagen 
mean(combine$AGE, na.rm = TRUE)
table(combine$AGE, useNA = "always") #min: 16. max: 103. consistent with Hagen.  

mean(combine$MALE, na.rm = TRUE) #mean = 0.8638, consistent with Hagen.   
table(combine$MALE, useNA = "always") #consistent with Hagen 

#percent high school or GED: 29.70, consistent with Hagen
mean(combine$HSGED, na.rm=TRUE)
table(combine$HSGED, useNA = "always") #consistent with Hagen 

#percent some post high school: 15.17, consistent with Hagen 
mean(combine$SOMEPOSTHS, na.rm=TRUE)
table(combine$SOMEPOSTHS, useNA = "always") #84,377 post-HS, consistent with Hagen. 

mean(combine$POSTHSDEGREE, na.rm = TRUE) #7.63, consistent with Hagen 
table(combine$POSTHSDEGREE, useNA = "always") #consistent with Hagen

#Hagen num obs: 618825
mean(combine$HISPANIC, na.rm = TRUE) #41.83. Hagen: 40.07. inconsistent because Hagen treats NAs as "Other"/0.
table(combine$HISPANIC) #247965, consistent with Hagen.

mean(combine$USCITIZEN, na.rm=TRUE) #63.63. Hagen: 60.79. inconsistent because Hagen treats NAs as 0s
table(combine$USCITIZEN, useNA = "always") #376,207 citizens, consistent with Hagen. 
sum(combine$USCITIZEN == 0 | is.na(combine$USCITIZEN)) #242,618

#Hagen num obs: 618825
mean(combine$CRIMINAL, na.rm=TRUE) #74.18. Hagen: 70.23. inconsistent because Hagen converts NAs to 0s. 
table(combine$CRIMINAL, useNA = "always") #434,616 with criminal history, consistent with Hagen.  
sum(combine$CRIMINAL, na.rm = TRUE)/length(combine$CATEGORY) #when I include NAs, the percent w/ crim hist = 70.23 

table(combine$CATEGORY, useNA = "always") #consistent with Hagen 

mean(combine$NOCOUNTS, na.rm = TRUE) #1.46, consistent with Hagen 
table(combine$NOCOUNTS, useNA = "always") #all categories are numeric except "imm"
#min = 0, max = 495, consistent with Hagen 

#the variable labeled POINTS in Hagen's Table 1 is actually CRPTS, which, instead of being a continuous variable as Hagen describes on p. 14, is a binary indicator of whether criminal points were applied 
mean(combine$POINTS, na.rm = TRUE)
table(combine$POINTS, useNA = "always") 

mean(combine$CRPTS, na.rm = TRUE) #59.91, consistent with Hagen 
table(combine$CRPTS, useNA = "always") #347142, consistent with Hagen 

mean(combine$TRIAL, na.rm=TRUE) #4.10%, consistent with Hagen
table(combine$TRIAL, useNA = "always") 

table(combine$YR, useNA = "always") #consistent with Hagen. 

table(combine$SWB, useNA = "always") #184881, consistent with Hagen.

table(combine$RACE, useNA = "always")

table(combine$PRIM_OFFENSE, useNA = "always") #INCONSISTENT
```

### Check covariance between variables 
```{r}
names(combine)
#sentence length increases with age of person arrested
cov(combine$SENTENCE, combine$AGE, use="complete.obs") #use=complete.obs removes observations by casewise ddeletion 
cov(combine$SENTENCE, combine$HISPANIC, use="complete.obs") #being hispanic is associated with decreased sentence length on average. this is consistent  

cov(combine$SENTENCE, combine$RACE=="black", use="complete.obs") #as expected, sentences are longer for Black people 
cov(combine$SENTENCE, combine$RACE =="white", use="complete.obs") #as expected, sentences are shorter for white people 
cov(combine$SENTENCE, combine$MALE, use="complete.obs") #men get longer sentences 
cov(combine$SENTENCE, combine$TRIAL, use="complete.obs") #as expected, people who go to trial get longer sentences
cor(combine$SENTENCE, combine$TRIAL, use="complete.obs")

cov(combine$POSTHSDEGREE, combine$HISPANIC, use="complete.obs") #being hispanic is associated with lower rate of post-secondary degree 
cor(combine$POSTHSDEGREE, combine$HISPANIC, use="complete.obs")

cov(combine$SENTENCE, combine$POSTHSDEGREE, use="complete.obs") #postsecondary degree is associated with shorter sentence 

cov(combine$SENTENCE, combine$CRIMINAL, use="complete.obs") #as expected, criminal history is associated with longer sentence 

cov(combine$SENTENCE, combine$USCITIZEN, use = "complete.obs") #unexpectedly, US citizenship is associated with longer sentences. my covariate-adjusted coefficient for citizenship has the opposite relationship.  
cor(combine$SENTENCE, combine$USCITIZEN, use="complete.obs")

cov(combine$SENTENCE, combine$PRIM_OFFENSE=="violent", use="complete.obs") #violent crimes get longer sentences than others

cov(combine$USCITIZEN, combine$PRIM_OFFENSE=="violent", use="complete.obs") 
cor(combine$USCITIZEN, combine$PRIM_OFFENSE=="violent", use="complete.obs") 
#US citizens are more likely to be sentenced for violent crimes than noncitizens 
```


### Mean sentence length by race, citizenship, Hispanic ethnicity 
```{r}
mean(combine$SENTENCE[combine$RACE=="black"], na.rm = TRUE) #90.57
mean(combine$SENTENCE[combine$RACE=="white"], na.rm = TRUE) #48.15
mean(combine$SENTENCE[combine$RACE == "aian"], na.rm=TRUE) #64.65 
mean(combine$SENTENCE[combine$RACE == "apic"], na.rm = TRUE) #46.70 
mean(combine$SENTENCE[combine$RACE == "multi"], na.rm = TRUE) #68.82 
mean(combine$SENTENCE[combine$USCITIZEN==1], na.rm = TRUE) #72.67
mean(combine$SENTENCE[combine$USCITIZEN==0], na.rm = TRUE) #37.70 
mean(combine$SENTENCE[combine$HISPANIC==1], na.rm = TRUE) #43.56
mean(combine$SENTENCE[combine$HISPANIC==0 & combine$RACE == "white"], na.rm = TRUE) #57.58 #non-hispanic white people have longer sentences on average than hispanic folks. this may be related to the selection bias that Hagen points out

#some differences in means, subset by crime category 
mean(combine$SENTENCE[combine$RACE=="black" & combine$PRIM_OFFENSE == "violent"], na.rm = TRUE) - mean(combine$SENTENCE[combine$RACE=="white" & combine$PRIM_OFFENSE == "violent"], na.rm = TRUE) #as expected, Black folks get longer sentences 

mean(combine$SENTENCE[combine$RACE=="black" & combine$PRIM_OFFENSE == "drugs"], na.rm = TRUE) - mean(combine$SENTENCE[combine$RACE=="white" & combine$PRIM_OFFENSE == "drugs"], na.rm = TRUE) #huge disparity for drug sentences

mean(combine$SENTENCE[combine$RACE=="black" & combine$PRIM_OFFENSE == "public order"], na.rm = TRUE) - mean(combine$SENTENCE[combine$RACE=="white" & combine$PRIM_OFFENSE == "public order"], na.rm = TRUE)

mean(combine$SENTENCE[combine$USCITIZEN==0 & combine$PRIM_OFFENSE == "violent"], na.rm = TRUE) - mean(combine$SENTENCE[combine$USCITIZEN==1 & combine$PRIM_OFFENSE == "violent"], na.rm = TRUE)
#noncitizens get longer sentences for violent crimes 
```

### Comparison to Hagen Table 4
```{r}
#subset data for immigration offenses 
imm <- combine[combine$PRIM_OFFENSE == "immigration" & !is.na(combine$PRIM_OFFENSE), ]
nrow(imm) #N = 138993. Hagen: 111774.

#split into SWB and non-SWB region 
imm_swb <- imm[imm$SWB == 1, ]
imm_notswb <- imm[imm$SWB == 0, ]
nrow(imm_swb) #93678. Hagen: 78695
nrow(imm_notswb) #45315. Hagen: 33079 

lm_imm_swb <- lm(SENTENCE ~ AGE + MALE + HSGED + SOMEPOSTHS + POSTHSDEGREE + HISPANIC + USCITIZEN + CRIMINAL + CATEGORY2 + CATEGORY3 + CATEGORY4 + CATEGORY5 + CATEGORY6 + NOCOUNTS + POINTS + TRIAL + YR2001 + YR2002 + YR2003 + YR2004 + YR2005 + YR2006 + YR2007 + YR2008, data = imm_swb)
summary(lm_imm_swb)
#main differences: my MALE coef is larger. my SOMEPOSTHS is smaller and not significant. my HISPANIC is smaller and not significant. my CRIMINAL is more negative, and significant. my POINTS is in opposite direction. 

lm_imm_notswb <- lm(SENTENCE ~ AGE + MALE + HSGED + SOMEPOSTHS + POSTHSDEGREE + HISPANIC + USCITIZEN + CRIMINAL + CATEGORY2 + CATEGORY3 + CATEGORY4 + CATEGORY5 + CATEGORY6 + NOCOUNTS + POINTS + TRIAL + YR2001 + YR2002 + YR2003 + YR2004 + YR2005 + YR2006 + YR2007 + YR2008, data = imm_notswb)
summary(lm_imm_notswb)
#my POINTS is in opposite direction, and significant. otherwise all same direction. 
```


