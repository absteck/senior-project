---
title: "sentencing plots binary response"
author: "Abby Steckel"
date: "10/18/2021"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Read data 
```{r, message=FALSE, warning=FALSE}
red <- '#A31F34'
blue <- '#325585'
## data manipulation
library(reshape2)
library(plyr)
library(stringr)

## math
library(Matrix)
library(MASS)
library(speedglm)
library(sandwich)

## graphics
library(ggplot2)
#library(Cairo) throwing an error, doesn't seem essential 

## parallel
library(foreach)
library(doMC)
registerDoMC(cores = 8)
#decompressing gz 
library(R.utils)
library(tidyverse)

combine <- read.csv('/Users/abbysteckel/Desktop/combined.csv.gz')
combine <- na_if(combine, "")
#subset to just Black or white folks 
df <- combine[combine$RACE %in% c("black", "white"), ]
df$RACE <- ifelse(df$RACE == "black", 1, 0)

```


```{r}
sentence.binary <- c('above median', 'below median')

median(df$SENTENCE, na.rm = TRUE) #36 

## set white as base level
races.abbr <- c('white', 'black')
races <- c('white', 'black')
df$race <- factor(df$RACE, labels = races)

outcome <- c('SENTENCE')
predictors <- c('AGE', 'MALE', 'HSGED', 'SOMEPOSTHS', 'POSTHSDEGREE', 'HISPANIC', 'USCITIZEN', 'CRIMINAL', 'CATEGORY2', 'CATEGORY3', 'CATEGORY4', 'CATEGORY5', 'CATEGORY6', 'NOCOUNTS', 'POINTS', 'TRIAL','YR2001', 'YR2002', 'YR2003', 'YR2004', 'YR2005', 'YR2006', 'YR2007', 'YR2008', 'PRIM_OFFENSE', 'race')

df <- na.omit(df[, c(outcome, predictors)])
df$sentence.binary <- ifelse(df$SENTENCE > median(df$SENTENCE), 1, 0)
```



```{r}
odds.to.mean <- function(x){ x / (x + 1) }
mean.to.odds <- function(x){ x / (1 - x) }
##################
## load results ##
##################

## bounds results
ndraws <- 5000
alpha <- .95
results.fname <- sprintf('bounds_results_n%s_alpha%s_sentence.binary.rds',
                         ndraws,
                         alpha * 100
                         )
results <- readRDS(results.fname)
results$n.minority <- sum(df$race == "black")

```


```{r}
####################################################################
## plausible values for proportion of racial stops                ##
## based on gelman fagan kiss (2007), analysis of nypd s&f policy ##
## and goel rao shroff(2016), precinct or prejudice               ##
####################################################################

## gfk table 1: racial differences in stop rates that cannot explained by
##   - crime type (violent / weapons / property / drug)
##   - racial group's criminality (as previous year's dcjs arrest rates)
##   - precincts
gfk17 <- read.csv('/Users/abbysteckel/Desktop/S&DS_491/KLM Replication Materials/GelmanFaganKissTable1.csv')
gfk17 <- dcast(melt(gfk17, variable.name = 'crime.type'), ... ~ parameter)

## gfk p820: convert to stops per prev year's arrest, by precinct & crime type
##   "rates of stops (compared with previous year’s arrests)
##    for each ethnic group, e^(µ+α_e)"
gfk17$whites.stops.per.arrest <- exp(gfk17$intercept + gfk17$whites)
gfk17$blacks.stops.per.arrest <- exp(gfk17$intercept + gfk17$blacks)

## gfk proportion of excess stops, by precinct & crime type
gfk17$blacks.stops.excess <-
  (gfk17$blacks.stops.per.arrest - gfk17$whites.stops.per.arrest) /
  gfk17$blacks.stops.per.arrest

## or simply do this:
all.equal(gfk17$blacks.stops.excess,
          1 - exp(gfk17$whites - gfk17$blacks),
          tolerance = 1e-6
          )

## gfk p817: "each of the three [black population proportion] categories
##            represents roughly 1/3 of the precincts"
prop.weights <- c(
  '<10%' = 1/3,
  '10-40%' = 1/3,
  '>40%' = 1/3
)
gfk17$prop.weight <- prop.weights[gfk17$prop.black]

## gfk figure 2: suspected crime type as percentage of all stops
crime.type.weights <- c(
  violent = .25,
  weapons = .44,
  property = .2,
  drug = .11
)
gfk17$crime.type.weight <- crime.type.weights[gfk17$crime.type]

## gfk racial stop proportions, based on
##   (a) minority stops per each previous year's minority arrest
##   (b) white stops per each previous year's white arrest
##   racially motivated stops are a-b, proportion of minority stops is (a-b)/a
##   we take weighted average of (a-b)/a by precinct type & crime type
black.rs.gfk <- weighted.mean(
  x = gfk17$blacks.stops.excess,
  w = gfk17$prop.weight * gfk17$crime.type.weight
)
## grs racial stop proportions
black.rs.grs <- (3.8 - 2.5) / 3.8

## vertical lines based on prior work
annotations <- data.frame(treat.race = 'black',
                          rho = black.rs.gfk,
                          text = 'GFK (2007)')



#################
## prep labels ##
#################

## labels for plots
results$thresh.label <- factor(
  sentence.binary[results$thresh],
  levels = sentence.binary,
  labels = gsub('\n', ' ', sentence.binary),
  ordered = TRUE
)

results$thresh.label.short <-
  results$thresh.label

results$race.label <- factor(
  results$treat.race,
  levels = c('black'),
  labels = c('Black civilians'),
  ordered = TRUE
)

results$mod.label <- factor(
  results$mod.type,
  levels = c('base', 'full'),
  labels = c('Baseline specification', 'Full specification'),
  ordered = TRUE
)

annotations$race.label <- factor(
  annotations$treat.race,
  levels = c('black'),
  labels = c('Black civilians'),
  ordered = TRUE
)
```

```{r}
##################################
## interpretation for main text ##
##################################

results$rho <- round(results$rho, 2)  # fix minor floating point issue

## naive atest, baseline specification
naive.black.base <- results[
  results$mod.type == 'base' &
    results$treat.race == 'black' &
    results$rho == 0 &
    results$qoi == 'atest',
  ]
## bias-corrected atest, baseline specification
biascorrect.black.base <- results[
  results$mod.type == 'base' &
    results$treat.race == 'black' &
    results$rho == round(black.rs.gfk, 2) &
    results$qoi == 'atest',
  ]



## baseline specification:
##   excess racially motivated handcuffs+ in hispanic and black encounters

## naive estimate for hispanic (vs white) x number of hispanic encounters
## plus naive estimate for black (vs white) x number of black encounters
naive.black.base$excess <-
  naive.black.base$est * naive.black.base$n.minority
naive.excess <- ## naive.hispanic.base$excess +
  naive.black.base$excess
## names(naive.excess) <- naive.hispanic.base$thresh.label.short
names(naive.excess) <- naive.black.base$thresh.label.short
## bias-corrected atest for hispanic (vs white) x number of hispanic encounters
## plus bias-corrected atest for black (vs white) x number of black encounters
biascorrect.black.base$excess <-
  biascorrect.black.base$est * biascorrect.black.base$n.minority
biascorrect.excess <-
  ## biascorrect.hispanic.base$excess +
  biascorrect.black.base$excess
## results
excess.base <-
  cbind('naive' = naive.excess, 'bias-corrected' = biascorrect.excess)
excess.base

```

```{r}
#################
## plot bounds ##
#################

thresh <- 1 

ggplot(results[results$thresh == thresh &
                 results$qoi == 'ates',
               ],
       aes(x = rho) #x-axis is value of rho 
       ) +
  geom_hline(yintercept = 0, #draw x-axis
             ) + 
  geom_ribbon(aes(ymin = min.cilo * nrow(df) / 1000, #QUESTION: should I be multiplying by nrow(df[race == black, ]) instead of entire sample size? sum(df$race == 'black') = 124381, so I don't think the CI should go above 124381. However, KLM appear to use nrow(entire dataframe). 
                  ymax = max.cihi * nrow(df) / 1000
                  ),
              fill = paste0(red, '80')
              ) +
  geom_ribbon(aes(ymin = min * nrow(df) / 1000,
                  ymax = max * nrow(df) / 1000,
                  fill = 'TE_S'
                  )
              ) +
  geom_line(aes(y = est * n.minority / 1000,
                linetype = 'TE_ST',
                ),
            results[results$thresh == thresh &
                      results$qoi == 'atest',
                    ],
            color = 'black',
            size = 1
            ) +
  geom_point(aes(y = est * nrow(df) / 1000,
                 color = 'naive'
                 ),
             data = results[results$thresh == thresh & results$rho == 0,],
             color = blue,
             size = 2
             ) +
  geom_errorbar(aes(ymin = est.cilo * nrow(df) / 1000,
                    ymax = est.cihi * nrow(df) / 1000,
                    color = 'naive'
                    ),
                data = results[results$thresh == thresh & results$rho == 0,],
                width = 1,
                size = 1
                ) +
  geom_vline(aes(xintercept = rho),
             data = annotations[annotations$treat.race == 'black',],
             size = .25
             ) +
  geom_text(aes(label = text),
            data = annotations[annotations$treat.race == 'black',],
            y = 1100,
            size = 5,
            hjust = 1,
            vjust = -.5,
            angle = 90
            ) +
  theme(legend.position = 'bottom',
        legend.key.size = unit(1, 'cm'),
        legend.spacing.x = unit(.05, 'cm'),
        panel.grid.minor = element_blank(),
        panel.grid.major = element_line(linetype = 'dashed')
        ) +
  guides(color = guide_legend(title = NULL, order = 1),
         linetype = guide_legend(title = NULL, order = 2),
         fill = guide_legend(title = NULL, order = 3)
         ) +
  scale_color_manual(
    name = 'x',
    values = c('naive' = blue,
               'TE_S' = NA,
               'TE_ST' = NA
               ),
    labels = c('naive' = expression('naïve ATE'['M=1'] %*% ' #{convicted}'),
               'TE_S' = expression('ATE'['M=1'] %*% ' #{convicted}'),
               'TE_ST' = expression('ATT'['M=1'] %*% ' #{convicted minorities}')
               )
  ) +
  scale_fill_manual(name = 'x',
                        values = c('naive' = NA,
                                   'TE_S' = red,
                                   'TE_ST' = NA
                                   ),
    labels = c('naive' = expression('naïve ATE'['M=1'] %*% ' #{convicted}'),
               'TE_S' = expression('ATE'['M=1'] %*% ' #{convicted}'),
               'TE_ST' = expression('ATT'['M=1'] %*% ' #{convicted minorities}')
               )
    ) +
  scale_linetype_manual(
    name = 'x',
    values = c('naive' = NA,
               'TE_S' = NA,
               'TE_ST' = 'dashed'
               ),
    labels = c('naive' = expression('naïve ATE'['M=1'] %*% ' #{convicted}'),
               'TE_S' = expression('ATE'['M=1'] %*% ' #{convicted}'),
               'TE_ST' = expression('ATT'['M=1'] %*% ' #{convicted minorities}')
               )
  ) +
  ylab('Civilians subject to racially\ndiscriminatory sentence\n(thousands)\n') +
  xlab('\nProportion of racially discriminatory convictions') +
  xlim(0, 1) +
  facet_grid(. ~ race.label) +
  theme(legend.text = element_text(size = 10))

```

